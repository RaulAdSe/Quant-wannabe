{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Naive Model - End-to-End Pipeline\n",
    "\n",
    "**Objective:** Build a complete ML pipeline, even if simple. Get something working first.\n",
    "\n",
    "## What we'll do:\n",
    "1. Create labels (target: is the trade profitable?)\n",
    "2. Create simple features (price-based only)\n",
    "3. Train a logistic regression with walk-forward validation\n",
    "4. Evaluate: Does our filter improve the baseline?\n",
    "\n",
    "## Key Concepts:\n",
    "- **No lookahead bias**: Features use only past data, labels use future data\n",
    "- **Walk-forward validation**: Train on past, test on future, slide window\n",
    "- **Meta-strategy**: We're filtering baseline signals, not generating new ones\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Import our utilities\n",
    "from data import load_all_data, compute_returns\n",
    "from features import compute_rolling_returns, compute_rolling_volatility, create_feature_matrix\n",
    "from labels import create_forward_return_labels, create_cost_adjusted_labels, analyze_label_distribution\n",
    "from metrics import compute_all_metrics, compare_strategies\n",
    "from backtesting import (compute_strategy_returns, compute_portfolio_returns, \n",
    "                         compute_equity_curve, apply_ml_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "trade_log, prices, glassnode = load_all_data()\n",
    "\n",
    "# Align trade_log and prices\n",
    "common_idx = trade_log.index.intersection(prices.index)\n",
    "common_assets = trade_log.columns.intersection(prices.columns)\n",
    "\n",
    "signals = trade_log.loc[common_idx, common_assets]\n",
    "prices_aligned = prices.loc[common_idx, common_assets]\n",
    "\n",
    "print(f\"Aligned data: {len(signals)} timestamps, {len(common_assets)} assets\")\n",
    "print(f\"Assets: {list(common_assets)}\")\n",
    "print(f\"Period: {signals.index.min()} to {signals.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Create Labels\n",
    "\n",
    "**The label answers:** \"If we follow the baseline signal at time t, will it be profitable?\"\n",
    "\n",
    "For simplicity:\n",
    "- Label = 1 if forward return > 0 (profitable)\n",
    "- Label = 0 if forward return <= 0 (not profitable)\n",
    "\n",
    "We only create labels when the baseline signal = 1 (long), because when signal = 0, we're in cash anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels with different horizons\n",
    "HORIZON = 8  # 8 periods = 1 day (3h * 8 = 24h)\n",
    "COST_THRESHOLD = 0.002  # 0.2% to cover round-trip costs\n",
    "\n",
    "labels = create_cost_adjusted_labels(\n",
    "    prices_aligned, \n",
    "    signals,\n",
    "    horizon=HORIZON,\n",
    "    entry_cost=0.001,\n",
    "    exit_cost=0.001\n",
    ")\n",
    "\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "label_stats = analyze_label_distribution(labels, signals)\n",
    "print(f\"  Overall positive rate: {label_stats['overall']['positive_rate']*100:.1f}%\")\n",
    "print(f\"  Total samples: {label_stats['overall']['total']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-asset label distribution\n",
    "print(\"\\nPer-asset label distribution:\")\n",
    "print(\"-\" * 50)\n",
    "for asset, stats in label_stats['per_asset'].items():\n",
    "    print(f\"{asset:6s}: {stats['positive_rate']*100:5.1f}% positive ({stats['total']} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Create Features\n",
    "\n",
    "**Simple features first** - we can add complexity later.\n",
    "\n",
    "Features at time t (using only information available at t):\n",
    "- Returns over last N periods\n",
    "- Volatility over last N periods\n",
    "- Current signal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple features\n",
    "# Return windows in 3-hour periods: 1=3h, 8=1d, 56=1w, 224=1m\n",
    "return_features = compute_rolling_returns(prices_aligned, windows=[1, 8, 56, 224])\n",
    "volatility_features = compute_rolling_volatility(prices_aligned, windows=[56, 224])\n",
    "\n",
    "# Combine features\n",
    "features = pd.concat([return_features, volatility_features], axis=1)\n",
    "\n",
    "print(f\"Feature matrix shape: {features.shape}\")\n",
    "print(f\"\\nFeatures created:\")\n",
    "for col in features.columns[:10]:\n",
    "    print(f\"  - {col}\")\n",
    "if len(features.columns) > 10:\n",
    "    print(f\"  ... and {len(features.columns) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_pct = features.isna().sum() / len(features) * 100\n",
    "print(\"Missing values (top 10):\")\n",
    "print(missing_pct.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Prepare Data for Modeling\n",
    "\n",
    "We need to:\n",
    "1. Stack data across assets (one model for all assets)\n",
    "2. Align features and labels\n",
    "3. Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def prepare_stacked_data(features, labels, signals):\n    \"\"\"\n    Prepare data by stacking across assets.\n    Returns X (features) and y (labels) with MultiIndex (timestamp, asset).\n    \n    IMPORTANT: Feature columns are renamed to be asset-agnostic\n    (e.g., 'ADA_return_1p' becomes 'return_1p') so that all assets\n    have the same feature names and can be stacked without NaN issues.\n    \"\"\"\n    data_rows = []\n    \n    for timestamp in labels.index:\n        if timestamp not in features.index:\n            continue\n            \n        for asset in labels.columns:\n            # Only include rows where signal = 1 (we're considering a long)\n            if signals.loc[timestamp, asset] != 1:\n                continue\n                \n            label_val = labels.loc[timestamp, asset]\n            if pd.isna(label_val):\n                continue\n            \n            # Get asset-specific features\n            feature_cols = [c for c in features.columns if c.startswith(asset + '_')]\n            if not feature_cols:\n                continue\n                \n            row_features = features.loc[timestamp, feature_cols]\n            \n            if row_features.isna().any():\n                continue\n            \n            # Rename features to be asset-agnostic (remove asset prefix)\n            # e.g., 'ADA_return_1p' -> 'return_1p'\n            renamed_features = {}\n            for col in feature_cols:\n                new_name = col.replace(asset + '_', '')\n                renamed_features[new_name] = row_features[col]\n            \n            data_rows.append({\n                'timestamp': timestamp,\n                'asset': asset,\n                'label': label_val,\n                **renamed_features\n            })\n    \n    df = pd.DataFrame(data_rows)\n    df = df.set_index(['timestamp', 'asset'])\n    \n    y = df['label']\n    X = df.drop('label', axis=1)\n    \n    return X, y\n\nX, y = prepare_stacked_data(features, labels, signals)\nprint(f\"Prepared data: X shape = {X.shape}, y shape = {y.shape}\")\nprint(f\"Feature columns: {list(X.columns)}\")\nprint(f\"Label distribution: {y.value_counts().to_dict()}\")\nprint(f\"Positive rate: {y.mean()*100:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Walk-Forward Validation\n",
    "\n",
    "**Critical**: We must use temporal splits, not random splits.\n",
    "\n",
    "Walk-forward scheme:\n",
    "```\n",
    "Time: ----1----2----3----4----5----6----7----8---->\n",
    "\n",
    "Fold 1: [TRAIN TRAIN TRAIN][TEST]\n",
    "Fold 2:      [TRAIN TRAIN TRAIN][TEST]\n",
    "Fold 3:           [TRAIN TRAIN TRAIN][TEST]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_cv(X, y, train_size, test_size, step_size=None):\n",
    "    \"\"\"\n",
    "    Generate walk-forward cross-validation splits.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature DataFrame with timestamp in index\n",
    "        y: Label Series with timestamp in index\n",
    "        train_size: Number of unique timestamps for training\n",
    "        test_size: Number of unique timestamps for testing\n",
    "        step_size: How many timestamps to step forward (default: test_size)\n",
    "    \n",
    "    Yields:\n",
    "        (train_idx, test_idx, fold_info) tuples\n",
    "    \"\"\"\n",
    "    if step_size is None:\n",
    "        step_size = test_size\n",
    "    \n",
    "    # Get unique timestamps\n",
    "    timestamps = X.index.get_level_values('timestamp').unique().sort_values()\n",
    "    n_timestamps = len(timestamps)\n",
    "    \n",
    "    fold = 0\n",
    "    start = 0\n",
    "    \n",
    "    while start + train_size + test_size <= n_timestamps:\n",
    "        train_end = start + train_size\n",
    "        test_end = train_end + test_size\n",
    "        \n",
    "        train_timestamps = timestamps[start:train_end]\n",
    "        test_timestamps = timestamps[train_end:test_end]\n",
    "        \n",
    "        train_idx = X.index.get_level_values('timestamp').isin(train_timestamps)\n",
    "        test_idx = X.index.get_level_values('timestamp').isin(test_timestamps)\n",
    "        \n",
    "        fold_info = {\n",
    "            'fold': fold,\n",
    "            'train_start': train_timestamps[0],\n",
    "            'train_end': train_timestamps[-1],\n",
    "            'test_start': test_timestamps[0],\n",
    "            'test_end': test_timestamps[-1],\n",
    "            'train_size': train_idx.sum(),\n",
    "            'test_size': test_idx.sum()\n",
    "        }\n",
    "        \n",
    "        yield train_idx, test_idx, fold_info\n",
    "        \n",
    "        start += step_size\n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CV parameters\n",
    "# Trade log has ~1200 timestamps, let's use:\n",
    "# - 60% for initial training (~720 timestamps)\n",
    "# - 10% test windows (~120 timestamps each)\n",
    "\n",
    "n_timestamps = X.index.get_level_values('timestamp').nunique()\n",
    "print(f\"Total unique timestamps: {n_timestamps}\")\n",
    "\n",
    "TRAIN_SIZE = int(n_timestamps * 0.6)  # 60% for training\n",
    "TEST_SIZE = int(n_timestamps * 0.1)   # 10% test windows\n",
    "STEP_SIZE = TEST_SIZE                  # Non-overlapping test sets\n",
    "\n",
    "print(f\"Train size: {TRAIN_SIZE} timestamps\")\n",
    "print(f\"Test size: {TEST_SIZE} timestamps\")\n",
    "print(f\"Step size: {STEP_SIZE} timestamps\")\n",
    "\n",
    "# Count folds\n",
    "n_folds = 0\n",
    "for _ in walk_forward_cv(X, y, TRAIN_SIZE, TEST_SIZE, STEP_SIZE):\n",
    "    n_folds += 1\n",
    "print(f\"Number of folds: {n_folds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Train Logistic Regression\n",
    "\n",
    "Simple model first. We'll try more complex models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model with scaling.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    model = LogisticRegression(\n",
    "        C=1.0,\n",
    "        class_weight='balanced',  # Handle class imbalance\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_scaled, y_train)\n",
    "    \n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run walk-forward validation\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "fold_results = []\n",
    "\n",
    "for train_idx, test_idx, fold_info in walk_forward_cv(X, y, TRAIN_SIZE, TEST_SIZE, STEP_SIZE):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model, scaler = train_logistic_regression(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Store predictions with index\n",
    "    pred_df = pd.DataFrame({\n",
    "        'probability': y_prob,\n",
    "        'prediction': y_pred,\n",
    "        'actual': y_test.values\n",
    "    }, index=y_test.index)\n",
    "    all_predictions.append(pred_df)\n",
    "    \n",
    "    # Compute fold metrics\n",
    "    fold_info['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    fold_info['precision'] = precision_score(y_test, y_pred, zero_division=0)\n",
    "    fold_info['recall'] = recall_score(y_test, y_pred, zero_division=0)\n",
    "    try:\n",
    "        fold_info['auc'] = roc_auc_score(y_test, y_prob)\n",
    "    except:\n",
    "        fold_info['auc'] = 0.5\n",
    "    \n",
    "    fold_results.append(fold_info)\n",
    "    \n",
    "    print(f\"Fold {fold_info['fold']}: Acc={fold_info['accuracy']:.3f}, \"\n",
    "          f\"Prec={fold_info['precision']:.3f}, Rec={fold_info['recall']:.3f}, \"\n",
    "          f\"AUC={fold_info['auc']:.3f}\")\n",
    "\n",
    "# Combine all predictions\n",
    "predictions_df = pd.concat(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of CV results\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WALK-FORWARD VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nMean Accuracy:  {results_df['accuracy'].mean():.3f} (+/- {results_df['accuracy'].std():.3f})\")\n",
    "print(f\"Mean Precision: {results_df['precision'].mean():.3f} (+/- {results_df['precision'].std():.3f})\")\n",
    "print(f\"Mean Recall:    {results_df['recall'].mean():.3f} (+/- {results_df['recall'].std():.3f})\")\n",
    "print(f\"Mean AUC:       {results_df['auc'].mean():.3f} (+/- {results_df['auc'].std():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Evaluate Meta-Strategy\n",
    "\n",
    "Now the key question: **Does filtering the baseline signals improve performance?**\n",
    "\n",
    "We apply the ML filter:\n",
    "```\n",
    "signal_ml[t,a] = signal_base[t,a] × 1[p̂(t,a) > τ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filtered_signals(predictions_df, signals, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Create filtered signals based on ML predictions.\n",
    "    \"\"\"\n",
    "    # Get timestamps where we have predictions\n",
    "    pred_timestamps = predictions_df.index.get_level_values('timestamp').unique()\n",
    "    \n",
    "    # Start with baseline signals for those timestamps\n",
    "    filtered = signals.loc[pred_timestamps].copy()\n",
    "    \n",
    "    # Apply ML filter\n",
    "    for (timestamp, asset), row in predictions_df.iterrows():\n",
    "        if row['probability'] <= threshold:\n",
    "            # Override signal to 0 (stay in cash)\n",
    "            filtered.loc[timestamp, asset] = 0\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different thresholds\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "# Get timestamps where we have predictions\n",
    "pred_timestamps = predictions_df.index.get_level_values('timestamp').unique()\n",
    "\n",
    "# Baseline signals and prices for comparison period\n",
    "baseline_signals = signals.loc[pred_timestamps]\n",
    "comparison_prices = prices_aligned.loc[pred_timestamps]\n",
    "\n",
    "# Baseline performance\n",
    "baseline_returns = compute_strategy_returns(baseline_signals, comparison_prices, transaction_cost=0.001)\n",
    "baseline_portfolio = compute_portfolio_returns(baseline_returns)\n",
    "baseline_metrics = compute_all_metrics(baseline_portfolio.dropna())\n",
    "\n",
    "print(\"BASELINE (During Test Period):\")\n",
    "print(f\"  Sharpe Ratio:  {baseline_metrics['sharpe_ratio']:.3f}\")\n",
    "print(f\"  Total Return:  {baseline_metrics['total_return']*100:.2f}%\")\n",
    "print(f\"  Max Drawdown:  {baseline_metrics['max_drawdown']*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ML-FILTERED STRATEGY (Different Thresholds):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "threshold_results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    filtered_signals = create_filtered_signals(predictions_df, signals, threshold)\n",
    "    \n",
    "    # Compute returns\n",
    "    filtered_returns = compute_strategy_returns(filtered_signals, comparison_prices, transaction_cost=0.001)\n",
    "    filtered_portfolio = compute_portfolio_returns(filtered_returns)\n",
    "    filtered_metrics = compute_all_metrics(filtered_portfolio.dropna())\n",
    "    \n",
    "    # Count trades\n",
    "    n_trades_baseline = baseline_signals.diff().abs().sum().sum() / 2\n",
    "    n_trades_filtered = filtered_signals.diff().abs().sum().sum() / 2\n",
    "    \n",
    "    result = {\n",
    "        'threshold': threshold,\n",
    "        'sharpe': filtered_metrics['sharpe_ratio'],\n",
    "        'total_return': filtered_metrics['total_return'],\n",
    "        'max_drawdown': filtered_metrics['max_drawdown'],\n",
    "        'n_trades': n_trades_filtered,\n",
    "        'trade_reduction': (n_trades_baseline - n_trades_filtered) / n_trades_baseline * 100\n",
    "    }\n",
    "    threshold_results.append(result)\n",
    "    \n",
    "    print(f\"\\nThreshold τ = {threshold}:\")\n",
    "    print(f\"  Sharpe Ratio:    {result['sharpe']:.3f} (baseline: {baseline_metrics['sharpe_ratio']:.3f})\")\n",
    "    print(f\"  Total Return:    {result['total_return']*100:.2f}%\")\n",
    "    print(f\"  Max Drawdown:    {result['max_drawdown']*100:.2f}%\")\n",
    "    print(f\"  Trade Reduction: {result['trade_reduction']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot threshold analysis\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Sharpe ratio vs threshold\n",
    "axes[0, 0].plot(threshold_df['threshold'], threshold_df['sharpe'], 'bo-', markersize=8)\n",
    "axes[0, 0].axhline(y=baseline_metrics['sharpe_ratio'], color='r', linestyle='--', label='Baseline')\n",
    "axes[0, 0].set_xlabel('Threshold (τ)')\n",
    "axes[0, 0].set_ylabel('Sharpe Ratio')\n",
    "axes[0, 0].set_title('Sharpe Ratio vs Threshold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Total return vs threshold\n",
    "axes[0, 1].plot(threshold_df['threshold'], threshold_df['total_return'] * 100, 'go-', markersize=8)\n",
    "axes[0, 1].axhline(y=baseline_metrics['total_return'] * 100, color='r', linestyle='--', label='Baseline')\n",
    "axes[0, 1].set_xlabel('Threshold (τ)')\n",
    "axes[0, 1].set_ylabel('Total Return (%)')\n",
    "axes[0, 1].set_title('Total Return vs Threshold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Max drawdown vs threshold\n",
    "axes[1, 0].plot(threshold_df['threshold'], threshold_df['max_drawdown'] * 100, 'ro-', markersize=8)\n",
    "axes[1, 0].axhline(y=baseline_metrics['max_drawdown'] * 100, color='b', linestyle='--', label='Baseline')\n",
    "axes[1, 0].set_xlabel('Threshold (τ)')\n",
    "axes[1, 0].set_ylabel('Max Drawdown (%)')\n",
    "axes[1, 0].set_title('Max Drawdown vs Threshold (Lower is Better)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trade reduction vs threshold\n",
    "axes[1, 1].plot(threshold_df['threshold'], threshold_df['trade_reduction'], 'mo-', markersize=8)\n",
    "axes[1, 1].set_xlabel('Threshold (τ)')\n",
    "axes[1, 1].set_ylabel('Trade Reduction (%)')\n",
    "axes[1, 1].set_title('Trade Reduction vs Threshold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Best Threshold Equity Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best threshold (highest Sharpe)\n",
    "best_threshold = threshold_df.loc[threshold_df['sharpe'].idxmax(), 'threshold']\n",
    "print(f\"Best threshold: {best_threshold} (Sharpe: {threshold_df['sharpe'].max():.3f})\")\n",
    "\n",
    "# Create filtered signals with best threshold\n",
    "best_filtered_signals = create_filtered_signals(predictions_df, signals, best_threshold)\n",
    "\n",
    "# Compute returns\n",
    "best_filtered_returns = compute_strategy_returns(best_filtered_signals, comparison_prices, transaction_cost=0.001)\n",
    "best_filtered_portfolio = compute_portfolio_returns(best_filtered_returns)\n",
    "\n",
    "# Plot equity curves\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "baseline_equity = compute_equity_curve(baseline_portfolio.dropna())\n",
    "filtered_equity = compute_equity_curve(best_filtered_portfolio.dropna())\n",
    "\n",
    "ax.plot(baseline_equity.index, baseline_equity.values, 'b-', linewidth=2, label='Baseline', alpha=0.7)\n",
    "ax.plot(filtered_equity.index, filtered_equity.values, 'g-', linewidth=2, label=f'ML Filtered (τ={best_threshold})')\n",
    "ax.axhline(y=1, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.set_title('Equity Curve Comparison: Baseline vs ML-Filtered Strategy', fontsize=14)\n",
    "ax.set_ylabel('Portfolio Value')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on all data to get feature importance\n",
    "model_final, scaler_final = train_logistic_regression(X, y)\n",
    "\n",
    "# Get feature importance (absolute coefficients)\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': model_final.coef_[0],\n",
    "    'abs_coefficient': np.abs(model_final.coef_[0])\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(\"-\" * 50)\n",
    "for i, row in importance.head(15).iterrows():\n",
    "    direction = '+' if row['coefficient'] > 0 else '-'\n",
    "    print(f\"{row['feature']:40s} {direction} ({row['abs_coefficient']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "top_features = importance.head(15)\n",
    "colors = ['green' if c > 0 else 'red' for c in top_features['coefficient']]\n",
    "\n",
    "ax.barh(range(len(top_features)), top_features['coefficient'], color=colors, alpha=0.7)\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.set_xlabel('Coefficient')\n",
    "ax.set_title('Top 15 Feature Importance (Logistic Regression Coefficients)')\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Summary & Next Steps\n",
    "\n",
    "### What we accomplished:\n",
    "1. Built a complete ML pipeline: features → labels → model → evaluation\n",
    "2. Implemented proper walk-forward validation (no lookahead)\n",
    "3. Evaluated the meta-strategy against baseline\n",
    "\n",
    "### Key findings:\n",
    "- [ ] Fill in after running the notebook\n",
    "\n",
    "### Next steps (Phase 2+):\n",
    "1. **Better features**: Add Glassnode on-chain metrics, technical indicators\n",
    "2. **Better models**: Try XGBoost, Random Forest\n",
    "3. **Regime detection**: Use HMM to identify market regimes\n",
    "4. **Threshold optimization**: More sophisticated threshold selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for later analysis\n",
    "output_dir = Path.cwd().parent / 'data' / 'processed'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "predictions_df.to_csv(output_dir / 'naive_model_predictions.csv')\n",
    "print(f\"Saved predictions to {output_dir / 'naive_model_predictions.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}