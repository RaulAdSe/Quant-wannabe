{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Iqana Quant Challenge - Final Submission\n",
    "\n",
    "**Author:** Raul Adell  \n",
    "**Date:** December 2024\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook presents a complete ML meta-strategy that improves the baseline trading strategy by **+140% Sharpe ratio** while reducing maximum drawdown by **69%**.\n",
    "\n",
    "### Key Results\n",
    "| Metric | Baseline | ML + Regime Filter | Improvement |\n",
    "|--------|----------|-------------------|-------------|\n",
    "| Sharpe Ratio | 2.68 | **6.46** | +140% |\n",
    "| Total Return | 41% | **70%** | +71% |\n",
    "| Max Drawdown | -31.4% | **-9.7%** | 69% better |\n",
    "\n",
    "### Core Insight\n",
    "**Knowing WHEN NOT to trade is as important as knowing when to trade.**  \n",
    "Using Hidden Markov Models to detect market regimes and avoiding trades during Bear markets is the single biggest performance driver.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from hmmlearn import hmm\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Local imports\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from data import load_all_data\n",
    "from features import compute_rolling_returns, compute_rolling_volatility, compute_rsi, compute_bollinger_bands\n",
    "from labels import create_cost_adjusted_labels\n",
    "from metrics import compute_all_metrics\n",
    "from backtesting import compute_strategy_returns, compute_portfolio_returns\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "trade_log, prices, glassnode = load_all_data()\n",
    "\n",
    "# Align data\n",
    "common_idx = trade_log.index.intersection(prices.index)\n",
    "common_assets = trade_log.columns.intersection(prices.columns)\n",
    "signals = trade_log.loc[common_idx, common_assets]\n",
    "prices_aligned = prices.loc[common_idx, common_assets]\n",
    "\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Timestamps: {len(signals)}\")\n",
    "print(f\"Assets: {list(common_assets)}\")\n",
    "print(f\"Date range: {signals.index[0].strftime('%Y-%m-%d')} to {signals.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Frequency: 3-hourly (8 periods/day)\")\n",
    "print(f\"\\nGlassnode features: {len(glassnode.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Plot 1: Price evolution (normalized)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Normalized prices\n",
    "normalized = prices_aligned / prices_aligned.iloc[0] * 100\n",
    "for asset in common_assets:\n",
    "    axes[0].plot(normalized.index, normalized[asset], label=asset, linewidth=1.5)\n",
    "axes[0].set_ylabel('Normalized Price (Base=100)')\n",
    "axes[0].set_title('Asset Price Evolution')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Signal distribution\n",
    "signal_pct = signals.mean() * 100\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(signal_pct)))\n",
    "bars = axes[1].bar(signal_pct.index, signal_pct.values, color=colors)\n",
    "axes[1].set_ylabel('% Time Long')\n",
    "axes[1].set_title('Baseline Strategy: Time in Long Position')\n",
    "axes[1].axhline(y=50, color='red', linestyle='--', alpha=0.5, label='50%')\n",
    "for bar, pct in zip(bars, signal_pct.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                 f'{pct:.0f}%', ha='center', va='bottom', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Plot 2: Returns distribution and correlation\n",
    "returns = prices_aligned.pct_change().dropna()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Returns distribution\n",
    "for asset in common_assets:\n",
    "    axes[0].hist(returns[asset]*100, bins=50, alpha=0.5, label=asset, density=True)\n",
    "axes[0].set_xlabel('Return (%)')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Return Distribution by Asset')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(-15, 15)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation heatmap\n",
    "corr = returns.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "            ax=axes[1], mask=mask, square=True, linewidths=0.5)\n",
    "axes[1].set_title('Asset Return Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average correlation with BTC: {corr['BTC'].drop('BTC').mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Baseline Strategy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline strategy\n",
    "signals_naive = signals.copy()\n",
    "signals_naive.index = signals_naive.index.tz_localize(None)\n",
    "prices_naive = prices_aligned.copy()\n",
    "prices_naive.index = prices_naive.index.tz_localize(None)\n",
    "\n",
    "baseline_returns = compute_strategy_returns(signals_naive, prices_naive, transaction_cost=0.001)\n",
    "baseline_portfolio = compute_portfolio_returns(baseline_returns)\n",
    "baseline_metrics = compute_all_metrics(baseline_portfolio.dropna())\n",
    "\n",
    "print(\"BASELINE STRATEGY PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Sharpe Ratio: {baseline_metrics['sharpe_ratio']:.2f}\")\n",
    "print(f\"Total Return: {baseline_metrics['total_return']*100:.1f}%\")\n",
    "print(f\"Annualized Return: {baseline_metrics['annualized_return']*100:.1f}%\")\n",
    "print(f\"Max Drawdown: {baseline_metrics['max_drawdown']*100:.1f}%\")\n",
    "print(f\"Win Rate: {baseline_metrics['win_rate']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Regime Detection with Hidden Markov Model\n",
    "\n",
    "The key insight: market behavior differs across regimes (Bull/Bear/Sideways). Using BTC as the market proxy, we detect latent regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit HMM for regime detection\n",
    "btc_prices = prices_aligned['BTC']\n",
    "btc_returns = btc_prices.pct_change().dropna()\n",
    "btc_vol = btc_returns.rolling(window=8).std()\n",
    "\n",
    "hmm_features = pd.DataFrame({\n",
    "    'return': btc_returns,\n",
    "    'volatility': btc_vol\n",
    "}).dropna()\n",
    "\n",
    "# Scale and fit HMM\n",
    "hmm_scaler = StandardScaler()\n",
    "hmm_scaled = hmm_scaler.fit_transform(hmm_features)\n",
    "\n",
    "N_STATES = 3\n",
    "model_hmm = hmm.GaussianHMM(n_components=N_STATES, covariance_type='full', n_iter=100, random_state=42)\n",
    "model_hmm.fit(hmm_scaled)\n",
    "\n",
    "hidden_states = model_hmm.predict(hmm_scaled)\n",
    "regimes = pd.Series(hidden_states, index=hmm_features.index, name='regime')\n",
    "\n",
    "# Label regimes by mean return\n",
    "regime_stats = []\n",
    "for state in range(N_STATES):\n",
    "    mask = regimes == state\n",
    "    state_returns = hmm_features.loc[mask, 'return']\n",
    "    regime_stats.append({\n",
    "        'state': state,\n",
    "        'mean_return': state_returns.mean() * 100,\n",
    "        'volatility': state_returns.std() * 100,\n",
    "        'count': mask.sum(),\n",
    "        'pct': mask.mean() * 100\n",
    "    })\n",
    "\n",
    "regime_df = pd.DataFrame(regime_stats)\n",
    "sorted_states = regime_df.sort_values('mean_return', ascending=False)['state'].values\n",
    "\n",
    "REGIME_LABELS = {\n",
    "    sorted_states[0]: 'Bull',\n",
    "    sorted_states[1]: 'Sideways',\n",
    "    sorted_states[2]: 'Bear'\n",
    "}\n",
    "\n",
    "regimes_labeled = regimes.map(REGIME_LABELS)\n",
    "\n",
    "print(\"REGIME DETECTION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "for state, label in REGIME_LABELS.items():\n",
    "    stats = regime_df[regime_df['state'] == state].iloc[0]\n",
    "    print(f\"{label:10s}: {stats['pct']:5.1f}% of data, mean return: {stats['mean_return']:+.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regimes\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# Localize for plotting\n",
    "btc_plot = btc_prices.copy()\n",
    "btc_plot.index = btc_plot.index.tz_localize(None)\n",
    "regimes_plot = regimes_labeled.copy()\n",
    "regimes_plot.index = regimes_plot.index.tz_localize(None)\n",
    "\n",
    "common_idx = btc_plot.index.intersection(regimes_plot.index)\n",
    "btc_plot = btc_plot.loc[common_idx]\n",
    "regimes_plot = regimes_plot.loc[common_idx]\n",
    "\n",
    "colors = {'Bull': 'green', 'Bear': 'red', 'Sideways': 'gray'}\n",
    "\n",
    "# Price with regime overlay\n",
    "axes[0].plot(btc_plot.index, btc_plot.values, 'k-', linewidth=1, alpha=0.7)\n",
    "for regime, color in colors.items():\n",
    "    mask = regimes_plot == regime\n",
    "    axes[0].fill_between(btc_plot.index, btc_plot.min(), btc_plot.max(),\n",
    "                         where=mask, alpha=0.3, color=color, label=regime)\n",
    "axes[0].set_ylabel('BTC Price')\n",
    "axes[0].set_title('BTC Price with HMM Regime Detection')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Regime distribution pie chart\n",
    "regime_counts = regimes_labeled.value_counts()\n",
    "axes[1].pie(regime_counts.values, labels=regime_counts.index, autopct='%1.1f%%',\n",
    "            colors=[colors[r] for r in regime_counts.index], startangle=90)\n",
    "axes[1].set_title('Regime Distribution in Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Feature Engineering\n",
    "\n",
    "We combine three feature types:\n",
    "1. **Price-based**: Returns and volatility at multiple horizons\n",
    "2. **Technical**: RSI, Bollinger Band position\n",
    "3. **On-chain**: Glassnode Bitcoin metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features\n",
    "# 1. Price-based features\n",
    "return_features = compute_rolling_returns(prices_aligned, windows=[1, 8, 56])\n",
    "vol_features = compute_rolling_volatility(prices_aligned, windows=[56])\n",
    "\n",
    "# 2. Technical indicators\n",
    "rsi_features = compute_rsi(prices_aligned, window=112)\n",
    "bb_features = compute_bollinger_bands(prices_aligned, window=160)\n",
    "\n",
    "price_features = pd.concat([return_features, vol_features, rsi_features, bb_features], axis=1)\n",
    "\n",
    "# 3. Glassnode on-chain features\n",
    "GLASSNODE_FEATURES = [\n",
    "    'btc_mvrv_z_score', 'btc_puell_multiple', 'reserve_risk',\n",
    "    'btc_fear_greed_index', 'btc_adjusted_sopr',\n",
    "    'btc_percent_upply_in_profit', 'btc_network_value_to_transactions_signal',\n",
    "    'btc_futures_perpetual_funding_rate_mean', 'vocdd', 'mvocdd',\n",
    "]\n",
    "available_gn = [f for f in GLASSNODE_FEATURES if f in glassnode.columns]\n",
    "gn_selected = glassnode[available_gn].copy()\n",
    "\n",
    "# Align Glassnode (daily) to signals (3-hourly) via forward-fill\n",
    "gn_aligned = pd.DataFrame(index=signals_naive.index)\n",
    "for col in available_gn:\n",
    "    aligned_values = []\n",
    "    for ts in signals_naive.index:\n",
    "        date = ts.normalize()\n",
    "        available_dates = gn_selected[col].dropna().index\n",
    "        available_dates = available_dates[available_dates <= date]\n",
    "        if len(available_dates) > 0:\n",
    "            aligned_values.append(gn_selected[col].loc[available_dates[-1]])\n",
    "        else:\n",
    "            aligned_values.append(np.nan)\n",
    "    gn_aligned[col] = aligned_values\n",
    "\n",
    "print(\"FEATURE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Price-based features: {len([c for c in price_features.columns if 'return' in c or 'volatility' in c])}\")\n",
    "print(f\"Technical indicators: {len([c for c in price_features.columns if 'rsi' in c or 'bb_' in c])}\")\n",
    "print(f\"Glassnode on-chain: {len(available_gn)}\")\n",
    "print(f\"Total features per asset: {6 + len(available_gn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Label Design & Data Preparation\n",
    "\n",
    "Labels: Binary classification - is the forward return (over 1 day) greater than transaction costs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "HORIZON = 8  # 1 day = 8 periods of 3 hours\n",
    "labels = create_cost_adjusted_labels(\n",
    "    prices_aligned, signals,\n",
    "    horizon=HORIZON,\n",
    "    entry_cost=0.001,\n",
    "    exit_cost=0.001\n",
    ")\n",
    "\n",
    "# Align regimes to signals\n",
    "regimes_labeled_naive = regimes_labeled.copy()\n",
    "regimes_labeled_naive.index = regimes_labeled_naive.index.tz_localize(None)\n",
    "\n",
    "regimes_aligned = pd.DataFrame(index=signals_naive.index)\n",
    "for ts in signals_naive.index:\n",
    "    if ts in regimes_labeled_naive.index:\n",
    "        regimes_aligned.loc[ts, 'regime'] = regimes_labeled_naive.loc[ts]\n",
    "    else:\n",
    "        available_ts = regimes_labeled_naive.index[regimes_labeled_naive.index <= ts]\n",
    "        if len(available_ts) > 0:\n",
    "            regimes_aligned.loc[ts, 'regime'] = regimes_labeled_naive.loc[available_ts[-1]]\n",
    "        else:\n",
    "            regimes_aligned.loc[ts, 'regime'] = np.nan\n",
    "\n",
    "print(f\"Label horizon: {HORIZON} periods ({HORIZON*3} hours)\")\n",
    "print(f\"Cost threshold: 0.2% (round-trip)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ML (stack across assets)\n",
    "def prepare_ml_data(price_features, gn_aligned, labels, signals):\n",
    "    \"\"\"Stack data across assets with asset-agnostic feature names.\"\"\"\n",
    "    data_rows = []\n",
    "    signals_naive = signals.copy()\n",
    "    signals_naive.index = signals_naive.index.tz_localize(None)\n",
    "    labels_naive = labels.copy()\n",
    "    labels_naive.index = labels_naive.index.tz_localize(None)\n",
    "    price_features_naive = price_features.copy()\n",
    "    price_features_naive.index = price_features_naive.index.tz_localize(None)\n",
    "    \n",
    "    for timestamp in labels_naive.index:\n",
    "        if timestamp not in price_features_naive.index or timestamp not in gn_aligned.index:\n",
    "            continue\n",
    "        for asset in labels_naive.columns:\n",
    "            if signals_naive.loc[timestamp, asset] != 1:  # Only when baseline says \"long\"\n",
    "                continue\n",
    "            label_val = labels_naive.loc[timestamp, asset]\n",
    "            if pd.isna(label_val):\n",
    "                continue\n",
    "            \n",
    "            # Get asset-specific price features\n",
    "            asset_cols = [c for c in price_features_naive.columns if c.startswith(asset + '_')]\n",
    "            if not asset_cols:\n",
    "                continue\n",
    "            price_row = price_features_naive.loc[timestamp, asset_cols]\n",
    "            if price_row.isna().any():\n",
    "                continue\n",
    "            \n",
    "            # Get Glassnode features\n",
    "            gn_row = gn_aligned.loc[timestamp]\n",
    "            if gn_row.isna().any():\n",
    "                continue\n",
    "            \n",
    "            # Rename to asset-agnostic\n",
    "            renamed_price = {col.replace(asset + '_', ''): price_row[col] for col in asset_cols}\n",
    "            row_data = {'timestamp': timestamp, 'asset': asset, 'label': label_val,\n",
    "                        **renamed_price, **gn_row.to_dict()}\n",
    "            data_rows.append(row_data)\n",
    "    \n",
    "    df = pd.DataFrame(data_rows).set_index(['timestamp', 'asset'])\n",
    "    return df.drop('label', axis=1), df['label']\n",
    "\n",
    "X, y = prepare_ml_data(price_features, gn_aligned, labels, signals)\n",
    "\n",
    "print(f\"\\nML DATA PREPARED\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Samples: {len(X)}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Positive rate (profitable trades): {y.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Model Training (Walk-Forward Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward split: 60% train, 40% test\n",
    "timestamps = X.index.get_level_values('timestamp').unique().sort_values()\n",
    "split_idx = int(len(timestamps) * 0.6)\n",
    "train_ts = timestamps[:split_idx]\n",
    "test_ts = timestamps[split_idx:]\n",
    "\n",
    "train_mask = X.index.get_level_values('timestamp').isin(train_ts)\n",
    "test_mask = X.index.get_level_values('timestamp').isin(test_ts)\n",
    "\n",
    "X_train, X_test = X[train_mask], X[test_mask]\n",
    "y_train, y_test = y[train_mask], y[test_mask]\n",
    "\n",
    "print(f\"Train period: {train_ts[0].strftime('%Y-%m-%d')} to {train_ts[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Test period: {test_ts[0].strftime('%Y-%m-%d')} to {test_ts[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"\\nTrain samples: {len(X_train)}, Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "top_n = 12\n",
    "top_features = importance.head(top_n)\n",
    "\n",
    "# Color by feature type\n",
    "colors = ['coral' if f in available_gn else 'steelblue' for f in top_features['feature']]\n",
    "\n",
    "ax.barh(range(len(top_features)), top_features['importance'], color=colors, alpha=0.7)\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title(f'Top {top_n} Feature Importance (Coral = On-chain, Blue = Technical)')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Strategy Evaluation: ML + Regime Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions DataFrame\n",
    "predictions_df = pd.DataFrame({'probability': y_prob}, index=y_test.index)\n",
    "pred_timestamps = predictions_df.index.get_level_values('timestamp').unique()\n",
    "\n",
    "# Get aligned data for evaluation\n",
    "baseline_signals = signals_naive.loc[pred_timestamps]\n",
    "comparison_prices = prices_naive.loc[pred_timestamps]\n",
    "\n",
    "# Apply ML + Regime filter\n",
    "THRESHOLD = 0.5\n",
    "ALLOWED_REGIMES = ['Bull', 'Sideways']\n",
    "\n",
    "filtered_signals = baseline_signals.copy()\n",
    "for (ts, asset), row in predictions_df.iterrows():\n",
    "    if asset not in filtered_signals.columns:\n",
    "        continue\n",
    "    \n",
    "    # ML filter: skip if probability below threshold\n",
    "    if row['probability'] <= THRESHOLD:\n",
    "        filtered_signals.loc[ts, asset] = 0\n",
    "        continue\n",
    "    \n",
    "    # Regime filter: skip if in Bear market\n",
    "    if ts in regimes_aligned.index:\n",
    "        current_regime = regimes_aligned.loc[ts, 'regime']\n",
    "        if current_regime not in ALLOWED_REGIMES:\n",
    "            filtered_signals.loc[ts, asset] = 0\n",
    "\n",
    "# Compute returns\n",
    "baseline_returns_test = compute_strategy_returns(baseline_signals, comparison_prices, transaction_cost=0.001)\n",
    "baseline_portfolio_test = compute_portfolio_returns(baseline_returns_test)\n",
    "baseline_metrics_test = compute_all_metrics(baseline_portfolio_test.dropna())\n",
    "\n",
    "filtered_returns = compute_strategy_returns(filtered_signals, comparison_prices, transaction_cost=0.001)\n",
    "filtered_portfolio = compute_portfolio_returns(filtered_returns)\n",
    "filtered_metrics = compute_all_metrics(filtered_portfolio.dropna())\n",
    "\n",
    "# Trade reduction\n",
    "total_signals = (baseline_signals == 1).sum().sum()\n",
    "kept_signals = (filtered_signals == 1).sum().sum()\n",
    "trade_reduction = (1 - kept_signals / total_signals) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"FINAL RESULTS: BASELINE vs ML + REGIME FILTER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'Metric':<25} {'Baseline':>15} {'ML+Regime':>15} {'Improvement':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "sharpe_imp = (filtered_metrics['sharpe_ratio'] - baseline_metrics_test['sharpe_ratio']) / baseline_metrics_test['sharpe_ratio'] * 100\n",
    "ret_imp = (filtered_metrics['total_return'] - baseline_metrics_test['total_return']) / baseline_metrics_test['total_return'] * 100\n",
    "dd_imp = (baseline_metrics_test['max_drawdown'] - filtered_metrics['max_drawdown']) / abs(baseline_metrics_test['max_drawdown']) * 100\n",
    "\n",
    "print(f\"{'Sharpe Ratio':<25} {baseline_metrics_test['sharpe_ratio']:>15.2f} {filtered_metrics['sharpe_ratio']:>15.2f} {sharpe_imp:>+14.1f}%\")\n",
    "print(f\"{'Total Return':<25} {baseline_metrics_test['total_return']*100:>14.1f}% {filtered_metrics['total_return']*100:>14.1f}% {ret_imp:>+14.1f}%\")\n",
    "print(f\"{'Max Drawdown':<25} {baseline_metrics_test['max_drawdown']*100:>14.1f}% {filtered_metrics['max_drawdown']*100:>14.1f}% {dd_imp:>+14.1f}%\")\n",
    "print(f\"{'Trade Reduction':<25} {'-':>15} {trade_reduction:>14.1f}% {'-':>15}\")\n",
    "\n",
    "print(f\"\\nConfiguration: Ï„={THRESHOLD}, Regimes={ALLOWED_REGIMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization: Equity curves and drawdowns\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Equity curves\n",
    "baseline_cumret = (1 + baseline_portfolio_test.dropna()).cumprod()\n",
    "filtered_cumret = (1 + filtered_portfolio.dropna()).cumprod()\n",
    "\n",
    "axes[0].plot(baseline_cumret.index, baseline_cumret.values, 'r-', linewidth=1.5, alpha=0.7, label='Baseline')\n",
    "axes[0].plot(filtered_cumret.index, filtered_cumret.values, 'b-', linewidth=2, label='ML + Regime Filter')\n",
    "axes[0].set_ylabel('Cumulative Return')\n",
    "axes[0].set_title('Equity Curves: Baseline vs ML + Regime Filter')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate final values\n",
    "axes[0].annotate(f'{baseline_cumret.iloc[-1]:.2f}x', \n",
    "                 xy=(baseline_cumret.index[-1], baseline_cumret.iloc[-1]),\n",
    "                 xytext=(10, 0), textcoords='offset points', color='red', fontsize=12)\n",
    "axes[0].annotate(f'{filtered_cumret.iloc[-1]:.2f}x', \n",
    "                 xy=(filtered_cumret.index[-1], filtered_cumret.iloc[-1]),\n",
    "                 xytext=(10, 0), textcoords='offset points', color='blue', fontsize=12)\n",
    "\n",
    "# Drawdowns\n",
    "def compute_drawdown(returns):\n",
    "    cumret = (1 + returns).cumprod()\n",
    "    running_max = cumret.cummax()\n",
    "    return (cumret - running_max) / running_max\n",
    "\n",
    "baseline_dd = compute_drawdown(baseline_portfolio_test.dropna())\n",
    "filtered_dd = compute_drawdown(filtered_portfolio.dropna())\n",
    "\n",
    "axes[1].fill_between(baseline_dd.index, 0, baseline_dd.values*100, alpha=0.3, color='red', label='Baseline')\n",
    "axes[1].fill_between(filtered_dd.index, 0, filtered_dd.values*100, alpha=0.5, color='blue', label='ML + Regime Filter')\n",
    "axes[1].set_ylabel('Drawdown (%)')\n",
    "axes[1].set_title('Drawdown Comparison')\n",
    "axes[1].legend(loc='lower left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate max drawdowns\n",
    "axes[1].axhline(y=baseline_dd.min()*100, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].axhline(y=filtered_dd.min()*100, color='blue', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Regime detection is the key driver**: Using HMM to identify Bull/Bear/Sideways regimes and avoiding trades during Bear markets provides the largest performance improvement.\n",
    "\n",
    "2. **On-chain features matter**: Glassnode metrics (MVRV, Fear & Greed, SOPR) are among the most important features, capturing market cycle information.\n",
    "\n",
    "3. **Quality over quantity**: Reducing trades by ~79% while improving both Sharpe and returns shows the baseline takes many low-quality trades.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **Regime detection lag**: HMM identifies regimes in hindsight; real-time detection has lag during transitions.\n",
    "\n",
    "2. **Bear-heavy test period**: 58% of data is in Bear regime; Bull performance is less tested.\n",
    "\n",
    "3. **BTC-centric regimes**: Using BTC regime for all assets may miss asset-specific dynamics.\n",
    "\n",
    "### When the Approach Fails\n",
    "\n",
    "1. During regime transitions (model is slow to adapt)\n",
    "2. In prolonged sideways markets (less clear signal)\n",
    "3. When altcoins decouple from BTC\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Add regime transition smoothing to reduce whipsaw\n",
    "2. Test asset-specific regime detection\n",
    "3. Implement confidence-weighted position sizing\n",
    "4. Add stop-loss rules for additional protection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
